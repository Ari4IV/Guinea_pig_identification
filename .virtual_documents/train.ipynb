


import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import os
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D
from tensorflow.keras.optimizers import SGD
from ipywidgets import interact_manual





data_dir = './images'  # 資料夾的路徑
breeds = ['Abyssinian', 'American', 'Silkie', 'Skinny']
images = []
labels = []

for idx, breed in enumerate(breeds):
    breed_dir = os.path.join(data_dir, breed)
    for img_name in os.listdir(breed_dir):
        if not img_name.startswith('.'):  # 排除隱藏檔案
            img_path = os.path.join(breed_dir, img_name)
            img = load_img(img_path, target_size=(128, 128))
            images.append(img_to_array(img))
            labels.append(idx)

# 轉換成 numpy array
x_data = np.array(images, dtype='float32') / 255.  # 正規化
y_data = to_categorical(labels, num_classes=len(breeds))





x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=42)





print(x_train.shape)
n = np.random.randint(x_train.shape[0])
plt.imshow(x_train[n], cmap='Greys')
plt.title(breeds[np.argmax(y_train[n])])
plt.show()





model = Sequential([
    Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(128, 128, 3)),
    MaxPooling2D(2, 2),
    Conv2D(64, (3, 3),padding='same', activation='relu'),
    MaxPooling2D(2, 2),
    Flatten(),
    Dense(128, activation='relu'),
    Dense(len(breeds), activation='softmax')
])





model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.01), metrics=['accuracy'])





model.summary()





history = model.fit(x_train, y_train, epochs=20, validation_data=(x_test, y_test))





fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 12))

# 繪製訓練與驗證損失
ax1.plot(history.history['loss'], color='b', label="Training loss")
ax1.plot(history.history['val_loss'], color='r', label="Validation loss")
ax1.set_xticks(np.arange(1, 10, 1))
ax1.set_yticks(np.arange(0, 1, 0.1))
ax1.set_title('Training and Validation Loss')
ax1.set_xlabel('Epochs')
ax1.set_ylabel('Loss')
ax1.legend()

# 繪製訓練與驗證準確率
ax2.plot(history.history['accuracy'], color='b', label="Training accuracy")
ax2.plot(history.history['val_accuracy'], color='r', label="Validation accuracy")
ax2.set_xticks(np.arange(1, 10, 1))
ax2.set_title('Training and Validation Accuracy')
ax2.set_xlabel('Epochs')
ax2.set_ylabel('Accuracy')
ax2.legend()


plt.tight_layout()
plt.show()





predictions = model.predict(x_test)





accuracy = np.mean(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1))
print(f"Accuracy: {accuracy:.2f}")





from sklearn.metrics import confusion_matrix
import seaborn as sns

# 计算混淆矩阵
confusion = confusion_matrix(np.argmax(y_test, axis=1), np.argmax(predictions, axis=1))

# 设置图表的大小
plt.figure(figsize=(8, 6))

# 使用热图（heatmap）绘制混淆矩阵
sns.heatmap(confusion, annot=True, fmt='d', cmap='Blues', xticklabels=breeds, yticklabels=breeds)

# 添加标签和标题
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')

plt.show()



model.save('./model/guinea_pig_model.h5')


import matplotlib.pyplot as plt
import numpy as np


plt.figure(figsize=(12, 6))
plt.plot(history.history['accuracy'], color='b', label="Training accuracy")
plt.plot(history.history['val_accuracy'], color='r', label="Validation accuracy")
plt.title('Training and Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.grid(True)

plt.show()


# 计算混淆矩阵
y_pred = model.predict(x_test)
y_pred_classes = np.argmax(y_pred, axis=1)
y_true = np.argmax(y_test, axis=1)
confusion = confusion_matrix(y_true, y_pred_classes)

# 计算敏感度（True Positive Rate）
# Sensitivity = TP / (TP + FN)
TP = confusion.diagonal()
FN = confusion.sum(axis=1) - TP
sensitivity = TP / (TP + FN)

# 创建敏感度图表
plt.figure(figsize=(12, 6))
plt.bar(breeds, sensitivity)
plt.title('Sensitivity for Each Class')
plt.xlabel('Class')
plt.ylabel('Sensitivity')
plt.xticks(rotation=45)
plt.grid(axis='y')

plt.show()


# 计算混淆矩阵
y_pred = model.predict(x_test)
y_pred_classes = np.argmax(y_pred, axis=1)
y_true = np.argmax(y_test, axis=1)
confusion = confusion_matrix(y_true, y_pred_classes)

# 计算特异性（Specificity）
# Specificity = TN / (TN + FP)
TN = confusion.sum() - confusion.sum(axis=0) - confusion.sum(axis=1) + confusion.diagonal()
FP = confusion.sum(axis=1) - confusion.diagonal()
specificity = TN / (TN + FP)

# 创建特异性图表
plt.figure(figsize=(12, 6))
plt.bar(breeds, specificity)
plt.title('Specificity for Each Class')
plt.xlabel('Class')
plt.ylabel('Specificity')
plt.xticks(rotation=45)
plt.grid(axis='y')

plt.show()


from sklearn.metrics import classification_report, confusion_matrix
# 计算混淆矩阵
y_pred = model.predict(x_test)
y_pred_classes = np.argmax(y_pred, axis=1)
y_true = np.argmax(y_test, axis=1)
confusion = confusion_matrix(y_true, y_pred_classes)

# 计算准确度、精确度、召回率和 F1 分数
accuracy = np.mean(y_pred_classes == y_true)
report = classification_report(y_true, y_pred_classes, target_names=breeds, output_dict=True)
precision = [report[breed]['precision'] for breed in breeds]
recall = [report[breed]['recall'] for breed in breeds]
f1_score = [report[breed]['f1-score'] for breed in breeds]

# 创建性能度量图表
plt.figure(figsize=(12, 6))
plt.bar(breeds, precision, label='Precision')
plt.bar(breeds, recall, label='Recall', alpha=0.5)
plt.bar(breeds, f1_score, label='F1 Score', alpha=0.5)
plt.title('Performance Metrics for Each Class')
plt.xlabel('Class')
plt.ylabel('Score')
plt.xticks(rotation=45)
plt.legend()
plt.grid(axis='y')

print(f"Accuracy: {accuracy:.2f}")
print("Classification Report:\n", classification_report(y_true, y_pred_classes, target_names=breeds))

plt.show()



